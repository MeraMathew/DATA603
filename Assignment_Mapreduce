from collections import defaultdict
import re
from spellchecker import SpellChecker
import PyPDF2
#DOB - 4 November 2000
# Function to extract text from PDF
def extract_text_from_pdf(pdf_path, start_page, num_pages):
    with open(pdf_path, 'rb') as file:
        pdf_reader = PyPDF2.PdfReader(file)
        total_pages = len(pdf_reader.pages)
        
        extracted_text = []
        for page_num in range(start_page, min(start_page + num_pages, total_pages)):
            page = pdf_reader.pages[page_num]
            extracted_text.append(page.extract_text())
        
        return extracted_text  # Return a list of extracted texts

# Map phase: Count word occurrences for each segment of text
def map_word_count(text_segments):
    word_count = defaultdict(int)
    
    for text in text_segments:
        words = re.findall(r'\b\w+\b', text.lower())
        for word in words:
            word_count[word] += 1
            
    return word_count

# Reduce phase: Combine counts from different segments
def reduce_word_count(word_counts):
    final_count = defaultdict(int)
    for count in word_counts:
        for word, cnt in count.items():
            final_count[word] += cnt
    return final_count

# PDF file path
pdf_path = "C:\\Users\\meera\\Desktop\\DATA 603\\HW\\Map_Reduce\\Harry_Potter_Half_Blood_Prince.pdf"

# Extract text for file1
text_segments_file1 = extract_text_from_pdf(pdf_path, 4941 - 1, 10)
text_segments_file2 = extract_text_from_pdf(pdf_path, 100 - 1, 10)

# Map phase
word_counts_file1 = map_word_count(text_segments_file1)
word_counts_file2 = map_word_count(text_segments_file2)

# Reduce phase
final_word_count_file1 = reduce_word_count([word_counts_file1])
final_word_count_file2 = reduce_word_count([word_counts_file2])

# Output results
print("Word count for file1:")
for word, count in final_word_count_file1.items():
    print(f"{word}: {count}")

print("\nWord count for file2:")
for word, count in final_word_count_file2.items():
    print(f"{word}: {count}")

# Count non-English words for file2
def count_non_english_words(text_segments):
    spell = SpellChecker()
    non_english_count = defaultdict(int)

    for text in text_segments:
        words = re.findall(r'\b\w+\b', text.lower())
        for word in words:
            if word not in spell:  # If the word is not found in the dictionary
                non_english_count[word] += 1

    return non_english_count

# Count non-English words in file2 text segments
non_english_count_file2 = count_non_english_words(text_segments_file2)

# Print non-English word count for file2
print("\nNon-English word count for file2:")
for word, count in non_english_count_file2.items():
    print(f"{word}: {count}")
